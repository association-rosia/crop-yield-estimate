# General
method: bayes

metric:
  name: cls/f1-score
  goal: maximize

run_cap: 1000

parameters:
  random_state:
    distribution: constant
    value: 42

  cv:
    distribution: constant
    value: 5

  limit_h:
    distribution: constant
    value: 5000

  limit_l:
    distribution: constant
    value: 500

  use_llm_imputation:
    distribution: categorical
    values: [ True, False ]

  smote_augmentation:
    distribution: categorical
    values: [ True, False ]

  great_augmentation:
    distribution: categorical
    values: [ True, False ]

  generated_file:
    distribution: categorical
    values: [ 'TrainGenerated-6038.csv', 'TrainGeneratedImputed-6038.csv' ]

  max_target_by_acre:
    distribution: categorical
    values: [ 'none', 25000 ]

  # Preprocessing
  delna_thr:
    distribution: uniform
    min: 0
    max: 1

  fillna:
    distribution: categorical
    values: [ 'none', 'KNNImputer' ]

  scale:
    distribution: constant
    value: 'none'

  # Model
  estimator_name:
    distribution: constant
    value: 'LightGBM'

  num_leaves:
    distribution: int_uniform
    min: 2
    max: 1024

  max_depth:
    distribution: int_uniform
    min: 1
    max: 100

  learning_rate:
    distribution: uniform
    min: 0
    max: 1

  n_estimators:
    distribution: int_uniform
    min: 100
    max: 1000
  
  class_weight:
    distribution: constant
    value: 'balanced'

  min_child_samples:
    distribution: int_uniform
    min: 1
    max: 100

  subsample: # bagging_fraction
    distribution: uniform
    min: 0
    max: 1

  colsample_bytree: # feature_fraction
    distribution: uniform
    min: 0
    max: 1

  reg_alpha:
    distribution: uniform
    min: 0
    max: 50

  reg_lambda:
    distribution: uniform
    min: 0
    max: 50

  verbose:
    distribution: constant
    value: -1